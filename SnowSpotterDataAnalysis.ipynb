{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9fecef-f03c-401a-88c1-5c0c2f964761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a347f26a-b689-4b9a-9574-64def678e69b",
   "metadata": {},
   "source": [
    "#### Read the netCDF file with xarray and then open it as a dataframe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e5b973-939a-4b85-9dd0-6690f717789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\"filepath\\\\filename.nc\")\n",
    "df = ds.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364e69c9-44e1-429c-9566-1fcab7314540",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Graphing Interception\n",
    "\n",
    "Now that we have a clean dataframe with datetime in one column and a median number correspoinding to the participant responses in another column, we can create a visualization of snow-interception throughout a water year. The snowgraph function performs the following:\n",
    "\n",
    " * If the median value for a given date is greater than or equal to a value of 0.6, we graph a light blue line corresponding to snow present in the canopy. \n",
    " \n",
    " * If the median value is less than or equal to 0.4, we graph a white line corresponding to no snow in the canopy. \n",
    "  \n",
    " * Finally, if the average value is between 0.4 and 0.6, we graph a red line corresponing to large amounts of disagreement between responses. \n",
    " \n",
    "The snowgraph function can be called with mindate and maxdate values corresponding to the minimum and maximum date to be graphed on the x-axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ab4bdd0-982c-43ab-9a67-0e24fb68897c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def snowgraph1(mindate, maxdate):\n",
    "    plt.figure(figsize = (20,10))\n",
    "    ax=plt.axes()\n",
    "    ax.set_facecolor('lightgrey')\n",
    "    for i in range(0, len(df)): \n",
    "        plt.yticks([]) \n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "        if df['median_final'][i] == 0:\n",
    "            plt.axvline(df['datetime'][i], color = 'white', alpha=0.9)\n",
    "        \n",
    "\n",
    "        if df['median_final'][i] == 1:\n",
    "            plt.axvline(df['datetime'][i], color ='lightblue', alpha=0.5)\n",
    "        \n",
    "        #optional addition: add red lines for datetimes where mean response was close to 0.5 (high participant disagreement). \n",
    "        #if df['mean_final'][i] > 0.45 and mean_final.value[i] < 0.55:\n",
    "            #plt.axvline(df['datetime'][i], color ='red', alpha=0.5)\n",
    "        \n",
    "        plt.xlim([pd.to_datetime(mindate),pd.to_datetime(maxdate)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9057fb3-b2d2-47cd-af61-674c3fa7067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowgraph('2021-10-01 13:56:05','2022-04-30 07:26:05')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a153ee-18e5-4dfb-8784-2d38596bc2b1",
   "metadata": {},
   "source": [
    "## Identify mean amount of time snow is persistent in the canopy.\n",
    "\n",
    "This function finds the average amount of time for consecutive median values of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99452094-30fe-4790-83d0-18f99d14b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "N2022 = xr.open_dataset(\"filepath\\\\filename.nc\")\n",
    "N2022 = N2022.to_pandas()\n",
    "N2021 = xr.open_dataset(\"filepath\\\\filename.nc\")\n",
    "N2021 = N2021.to_pandas()\n",
    "N2020 = xr.open_dataset(\"filepath\\\\filename.nc\")\n",
    "N2020 = N2020.to_pandas()\n",
    "N2019 = xr.open_dataset(\"filepath\\\\filename.nc\")\n",
    "N2019 = N2019.to_pandas()\n",
    "N2018 = xr.open_dataset(\"filepath\\\\filename.nc\")\n",
    "N2018 = N2018.to_pandas()\n",
    "N2017 = xr.open_dataset(\"filepath\\\\filename.nc\")\n",
    "N2017 = N2017.to_pandas()\n",
    "N2016 = xr.open_dataset(\"filepath\\\\filename.nc\")\n",
    "N2016 = N2016.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d499444b-8fee-4be6-a2df-910ddc493a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration(year):\n",
    "    df = year\n",
    "    df1 = df.dropna(subset=['median_value']).reset_index(drop=True)\n",
    "\n",
    "    consecutive_series = []\n",
    "    current_series_start = None\n",
    "\n",
    "    for index, row in df1.iterrows():\n",
    "        if row['median_value'] == 1:\n",
    "            if current_series_start is None:\n",
    "                current_series_start = row['datetime']\n",
    "        elif current_series_start is not None:\n",
    "            consecutive_series.append((current_series_start, row['datetime']))\n",
    "            current_series_start = None\n",
    "\n",
    "    # Calculate the average time difference for each consecutive series of 1 values\n",
    "    time_diff = pd.Series([end - start for start, end in consecutive_series])\n",
    "    average_time_diff = pd.Series([end - start for start, end in consecutive_series]).mean()\n",
    "    converted_diff = (time_diff.dt.seconds)/3600\n",
    "    plt.hist(converted_diff, label = year, stacked = True, bins = range(30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
